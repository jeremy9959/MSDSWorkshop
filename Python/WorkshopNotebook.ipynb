{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "This is an example of a long,\n",
    "multiline string, such as a paragraph,\n",
    "entered as a string constant into a Python\n",
    "program.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is an example of a long,\\nmultiline string, such as a paragraph,\\nentered as a string constant into a Python\\nprogram.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example', 'of', 'a', 'long,', 'multiline', 'string,', 'such', 'as', 'a', 'paragraph,', 'entered', 'as', 'a', 'string', 'constant', 'into', 'a', 'Python', 'program.']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'This': 1,\n",
       "         'is': 1,\n",
       "         'an': 1,\n",
       "         'example': 1,\n",
       "         'of': 1,\n",
       "         'a': 4,\n",
       "         'long,': 1,\n",
       "         'multiline': 1,\n",
       "         'string,': 1,\n",
       "         'such': 1,\n",
       "         'as': 2,\n",
       "         'paragraph,': 1,\n",
       "         'entered': 1,\n",
       "         'string': 1,\n",
       "         'constant': 1,\n",
       "         'into': 1,\n",
       "         'Python': 1,\n",
       "         'program.': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['This']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 4), ('as', 2), ('This', 1), ('is', 1), ('an', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Counter(\"this is a string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Counter' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y(\u001b[39m'\u001b[39;49m\u001b[39mthis is a string\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Counter' object is not callable"
     ]
    }
   ],
   "source": [
    "for x in \"this is a string\":\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 3), ('s', 3), (' ', 3), ('t', 2), ('h', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'a',\n",
       " 'long,',\n",
       " 'multiline',\n",
       " 'string,',\n",
       " 'such',\n",
       " 'as',\n",
       " 'a',\n",
       " 'paragraph,',\n",
       " 'entered',\n",
       " 'as',\n",
       " 'a',\n",
       " 'string',\n",
       " 'constant',\n",
       " 'into',\n",
       " 'a',\n",
       " 'Python',\n",
       " 'program.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =\"1,2,3,4,5,6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeremy9959/GitHub/MSDSWorkshop/Python\n"
     ]
    }
   ],
   "source": [
    "cd Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tokenization is the process of demarcating and possibly classifying sections of a string of input characters. The resulting tokens are then passed on to some other form of processing. The process can be considered a sub-task of parsing input.\\n\\nFor example, in the text string:\\n\\n    The quick brown fox jumps over the lazy dog\\n\\nthe string isn\\'t implicitly segmented on spaces, as a natural language speaker would do. The raw input, the 43 characters, must be explicitly split into the 9 tokens with a given space delimiter (i.e., matching the string \" \" or regular expression /\\\\s{1}/).\\n\\nWhen a token class represents more than one possible lexeme, the lexer often saves enough information to reproduce the original lexeme, so that it can be used in semantic analysis. The parser typically retrieves this information from the lexer and stores it in the abstract syntax tree. This is necessary in order to avoid information loss in the case where numbers may also be valid identifiers.\\n\\nTokens are identified based on the specific rules of the lexer. Some methods used to identify tokens include: regular expressions, specific sequences of characters termed a flag, specific separating characters called delimiters, and explicit definition by a dictionary. Special characters, including punctuation characters, are commonly used by lexers to identify tokens because of their natural use in written and programming languages.\\n\\nTokens are often categorized by character content or by context within the data stream. Categories are defined by the rules of the lexer. Categories often involve grammar elements of the language used in the data stream. Programming languages often categorize tokens as identifiers, operators, grouping symbols, or by data type. Written languages commonly categorize tokens as nouns, verbs, adjectives, or punctuation. Categories are used for post-processing of the tokens either by the parser or by other functions in the program.\\n\\nA lexical analyzer generally does nothing with combinations of tokens, a task left for a parser. For example, a typical lexical analyzer recognizes parentheses as tokens, but does nothing to ensure that each \"(\" is matched with a \")\".\\n\\nWhen a lexer feeds tokens to the parser, the representation used is typically an enumerated list of number representations. For example, \"Identifier\" is represented with 0, \"Assignment operator\" with 1, \"Addition operator\" with 2, etc.\\n\\nTokens are defined often by regular expressions, which are understood by a lexical analyzer generator such as lex. The lexical analyzer (generated automatically by a tool like lex, or hand-crafted) reads in a stream of characters, identifies the lexemes in the stream, and categorizes them into tokens. This is termed tokenizing. If the lexer finds an invalid token, it will report an error.\\n\\nFollowing tokenizing is parsing. From there, the interpreted data may be loaded into data structures for general use, interpretation, or compiling. \\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "astrings = re.findall(r\"a\\w+\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ation',\n",
       " 'arcating',\n",
       " 'and',\n",
       " 'assifying',\n",
       " 'aracters',\n",
       " 'are',\n",
       " 'assed',\n",
       " 'an',\n",
       " 'ask',\n",
       " 'arsing',\n",
       " 'ample',\n",
       " 'azy',\n",
       " 'aces',\n",
       " 'as',\n",
       " 'atural',\n",
       " 'anguage',\n",
       " 'aker',\n",
       " 'aw',\n",
       " 'aracters',\n",
       " 'ace',\n",
       " 'atching',\n",
       " 'ar',\n",
       " 'ass',\n",
       " 'an',\n",
       " 'aves',\n",
       " 'ation',\n",
       " 'al',\n",
       " 'at',\n",
       " 'an',\n",
       " 'antic',\n",
       " 'analysis',\n",
       " 'arser',\n",
       " 'ally',\n",
       " 'ation',\n",
       " 'and',\n",
       " 'abstract',\n",
       " 'ax',\n",
       " 'ary',\n",
       " 'avoid',\n",
       " 'ation',\n",
       " 'ase',\n",
       " 'ay',\n",
       " 'also',\n",
       " 'alid',\n",
       " 'are',\n",
       " 'ased',\n",
       " 'ar',\n",
       " 'aracters',\n",
       " 'ag',\n",
       " 'arating',\n",
       " 'aracters',\n",
       " 'alled',\n",
       " 'and',\n",
       " 'ary',\n",
       " 'al',\n",
       " 'aracters',\n",
       " 'ation',\n",
       " 'aracters',\n",
       " 'are',\n",
       " 'ause',\n",
       " 'atural',\n",
       " 'and',\n",
       " 'amming',\n",
       " 'anguages',\n",
       " 'are',\n",
       " 'ategorized',\n",
       " 'aracter',\n",
       " 'ata',\n",
       " 'am',\n",
       " 'ategories',\n",
       " 'are',\n",
       " 'ategories',\n",
       " 'ammar',\n",
       " 'anguage',\n",
       " 'ata',\n",
       " 'am',\n",
       " 'amming',\n",
       " 'anguages',\n",
       " 'ategorize',\n",
       " 'as',\n",
       " 'ators',\n",
       " 'ata',\n",
       " 'anguages',\n",
       " 'ategorize',\n",
       " 'as',\n",
       " 'adjectives',\n",
       " 'ation',\n",
       " 'ategories',\n",
       " 'are',\n",
       " 'arser',\n",
       " 'am',\n",
       " 'al',\n",
       " 'analyzer',\n",
       " 'ally',\n",
       " 'ations',\n",
       " 'ask',\n",
       " 'arser',\n",
       " 'ample',\n",
       " 'al',\n",
       " 'al',\n",
       " 'analyzer',\n",
       " 'arentheses',\n",
       " 'as',\n",
       " 'at',\n",
       " 'ach',\n",
       " 'atched',\n",
       " 'arser',\n",
       " 'ation',\n",
       " 'ally',\n",
       " 'an',\n",
       " 'ated',\n",
       " 'ations',\n",
       " 'ample',\n",
       " 'ator',\n",
       " 'ator',\n",
       " 'are',\n",
       " 'ar',\n",
       " 'are',\n",
       " 'al',\n",
       " 'analyzer',\n",
       " 'ator',\n",
       " 'as',\n",
       " 'al',\n",
       " 'analyzer',\n",
       " 'ated',\n",
       " 'automatically',\n",
       " 'and',\n",
       " 'afted',\n",
       " 'ads',\n",
       " 'am',\n",
       " 'aracters',\n",
       " 'am',\n",
       " 'and',\n",
       " 'ategorizes',\n",
       " 'an',\n",
       " 'alid',\n",
       " 'an',\n",
       " 'arsing',\n",
       " 'ata',\n",
       " 'ay',\n",
       " 'aded',\n",
       " 'ata',\n",
       " 'al',\n",
       " 'ation']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "awords = re.findall(r\"\\ba\\w+\\b\",text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'abstract',\n",
       " 'avoid',\n",
       " 'also',\n",
       " 'are',\n",
       " 'and',\n",
       " 'are',\n",
       " 'and',\n",
       " 'are',\n",
       " 'are',\n",
       " 'as',\n",
       " 'as',\n",
       " 'adjectives',\n",
       " 'are',\n",
       " 'analyzer',\n",
       " 'analyzer',\n",
       " 'as',\n",
       " 'an',\n",
       " 'are',\n",
       " 'are',\n",
       " 'analyzer',\n",
       " 'as',\n",
       " 'analyzer',\n",
       " 'automatically',\n",
       " 'and',\n",
       " 'an',\n",
       " 'an']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'demarcating',\n",
       " 'and',\n",
       " 'possibly',\n",
       " 'classifying',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'string',\n",
       " 'of',\n",
       " 'input',\n",
       " 'characters',\n",
       " 'The',\n",
       " 'resulting',\n",
       " 'tokens',\n",
       " 'are',\n",
       " 'then',\n",
       " 'passed',\n",
       " 'on',\n",
       " 'to',\n",
       " 'some',\n",
       " 'other',\n",
       " 'form',\n",
       " 'of',\n",
       " 'processing',\n",
       " 'The',\n",
       " 'process',\n",
       " 'can',\n",
       " 'be',\n",
       " 'considered',\n",
       " 'sub',\n",
       " 'task',\n",
       " 'of',\n",
       " 'parsing',\n",
       " 'input',\n",
       " 'For',\n",
       " 'example',\n",
       " 'in',\n",
       " 'the',\n",
       " 'text',\n",
       " 'string',\n",
       " 'The',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumps',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " 'the',\n",
       " 'string',\n",
       " 'isn',\n",
       " 'implicitly',\n",
       " 'segmented',\n",
       " 'on',\n",
       " 'spaces',\n",
       " 'as',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'speaker',\n",
       " 'would',\n",
       " 'do',\n",
       " 'The',\n",
       " 'raw',\n",
       " 'input',\n",
       " 'the',\n",
       " '43',\n",
       " 'characters',\n",
       " 'must',\n",
       " 'be',\n",
       " 'explicitly',\n",
       " 'split',\n",
       " 'into',\n",
       " 'the',\n",
       " 'tokens',\n",
       " 'with',\n",
       " 'given',\n",
       " 'space',\n",
       " 'delimiter',\n",
       " 'matching',\n",
       " 'the',\n",
       " 'string',\n",
       " 'or',\n",
       " 'regular',\n",
       " 'expression',\n",
       " 'When',\n",
       " 'token',\n",
       " 'class',\n",
       " 'represents',\n",
       " 'more',\n",
       " 'than',\n",
       " 'one',\n",
       " 'possible',\n",
       " 'lexeme',\n",
       " 'the',\n",
       " 'lexer',\n",
       " 'often',\n",
       " 'saves',\n",
       " 'enough',\n",
       " 'information',\n",
       " 'to',\n",
       " 'reproduce',\n",
       " 'the',\n",
       " 'original',\n",
       " 'lexeme',\n",
       " 'so',\n",
       " 'that',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'in',\n",
       " 'semantic',\n",
       " 'analysis',\n",
       " 'The',\n",
       " 'parser',\n",
       " 'typically',\n",
       " 'retrieves',\n",
       " 'this',\n",
       " 'information',\n",
       " 'from',\n",
       " 'the',\n",
       " 'lexer',\n",
       " 'and',\n",
       " 'stores',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'abstract',\n",
       " 'syntax',\n",
       " 'tree',\n",
       " 'This',\n",
       " 'is',\n",
       " 'necessary',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'avoid',\n",
       " 'information',\n",
       " 'loss',\n",
       " 'in',\n",
       " 'the',\n",
       " 'case',\n",
       " 'where',\n",
       " 'numbers',\n",
       " 'may',\n",
       " 'also',\n",
       " 'be',\n",
       " 'valid',\n",
       " 'identifiers',\n",
       " 'Tokens',\n",
       " 'are',\n",
       " 'identified',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'specific',\n",
       " 'rules',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lexer',\n",
       " 'Some',\n",
       " 'methods',\n",
       " 'used',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'tokens',\n",
       " 'include',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " 'specific',\n",
       " 'sequences',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'termed',\n",
       " 'flag',\n",
       " 'specific',\n",
       " 'separating',\n",
       " 'characters',\n",
       " 'called',\n",
       " 'delimiters',\n",
       " 'and',\n",
       " 'explicit',\n",
       " 'definition',\n",
       " 'by',\n",
       " 'dictionary',\n",
       " 'Special',\n",
       " 'characters',\n",
       " 'including',\n",
       " 'punctuation',\n",
       " 'characters',\n",
       " 'are',\n",
       " 'commonly',\n",
       " 'used',\n",
       " 'by',\n",
       " 'lexers',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'tokens',\n",
       " 'because',\n",
       " 'of',\n",
       " 'their',\n",
       " 'natural',\n",
       " 'use',\n",
       " 'in',\n",
       " 'written',\n",
       " 'and',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'Tokens',\n",
       " 'are',\n",
       " 'often',\n",
       " 'categorized',\n",
       " 'by',\n",
       " 'character',\n",
       " 'content',\n",
       " 'or',\n",
       " 'by',\n",
       " 'context',\n",
       " 'within',\n",
       " 'the',\n",
       " 'data',\n",
       " 'stream',\n",
       " 'Categories',\n",
       " 'are',\n",
       " 'defined',\n",
       " 'by',\n",
       " 'the',\n",
       " 'rules',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lexer',\n",
       " 'Categories',\n",
       " 'often',\n",
       " 'involve',\n",
       " 'grammar',\n",
       " 'elements',\n",
       " 'of',\n",
       " 'the',\n",
       " 'language',\n",
       " 'used',\n",
       " 'in',\n",
       " 'the',\n",
       " 'data',\n",
       " 'stream',\n",
       " 'Programming',\n",
       " 'languages',\n",
       " 'often',\n",
       " 'categorize',\n",
       " 'tokens',\n",
       " 'as',\n",
       " 'identifiers',\n",
       " 'operators',\n",
       " 'grouping',\n",
       " 'symbols',\n",
       " 'or',\n",
       " 'by',\n",
       " 'data',\n",
       " 'type',\n",
       " 'Written',\n",
       " 'languages',\n",
       " 'commonly',\n",
       " 'categorize',\n",
       " 'tokens',\n",
       " 'as',\n",
       " 'nouns',\n",
       " 'verbs',\n",
       " 'adjectives',\n",
       " 'or',\n",
       " 'punctuation',\n",
       " 'Categories',\n",
       " 'are',\n",
       " 'used',\n",
       " 'for',\n",
       " 'post',\n",
       " 'processing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'tokens',\n",
       " 'either',\n",
       " 'by',\n",
       " 'the',\n",
       " 'parser',\n",
       " 'or',\n",
       " 'by',\n",
       " 'other',\n",
       " 'functions',\n",
       " 'in',\n",
       " 'the',\n",
       " 'program',\n",
       " 'lexical',\n",
       " 'analyzer',\n",
       " 'generally',\n",
       " 'does',\n",
       " 'nothing',\n",
       " 'with',\n",
       " 'combinations',\n",
       " 'of',\n",
       " 'tokens',\n",
       " 'task',\n",
       " 'left',\n",
       " 'for',\n",
       " 'parser',\n",
       " 'For',\n",
       " 'example',\n",
       " 'typical',\n",
       " 'lexical',\n",
       " 'analyzer',\n",
       " 'recognizes',\n",
       " 'parentheses',\n",
       " 'as',\n",
       " 'tokens',\n",
       " 'but',\n",
       " 'does',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'that',\n",
       " 'each',\n",
       " 'is',\n",
       " 'matched',\n",
       " 'with',\n",
       " 'When',\n",
       " 'lexer',\n",
       " 'feeds',\n",
       " 'tokens',\n",
       " 'to',\n",
       " 'the',\n",
       " 'parser',\n",
       " 'the',\n",
       " 'representation',\n",
       " 'used',\n",
       " 'is',\n",
       " 'typically',\n",
       " 'an',\n",
       " 'enumerated',\n",
       " 'list',\n",
       " 'of',\n",
       " 'number',\n",
       " 'representations',\n",
       " 'For',\n",
       " 'example',\n",
       " 'Identifier',\n",
       " 'is',\n",
       " 'represented',\n",
       " 'with',\n",
       " 'Assignment',\n",
       " 'operator',\n",
       " 'with',\n",
       " 'Addition',\n",
       " 'operator',\n",
       " 'with',\n",
       " 'etc',\n",
       " 'Tokens',\n",
       " 'are',\n",
       " 'defined',\n",
       " 'often',\n",
       " 'by',\n",
       " 'regular',\n",
       " 'expressions',\n",
       " 'which',\n",
       " 'are',\n",
       " 'understood',\n",
       " 'by',\n",
       " 'lexical',\n",
       " 'analyzer',\n",
       " 'generator',\n",
       " 'such',\n",
       " 'as',\n",
       " 'lex',\n",
       " 'The',\n",
       " 'lexical',\n",
       " 'analyzer',\n",
       " 'generated',\n",
       " 'automatically',\n",
       " 'by',\n",
       " 'tool',\n",
       " 'like',\n",
       " 'lex',\n",
       " 'or',\n",
       " 'hand',\n",
       " 'crafted',\n",
       " 'reads',\n",
       " 'in',\n",
       " 'stream',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'identifies',\n",
       " 'the',\n",
       " 'lexemes',\n",
       " 'in',\n",
       " 'the',\n",
       " 'stream',\n",
       " 'and',\n",
       " 'categorizes',\n",
       " 'them',\n",
       " 'into',\n",
       " 'tokens',\n",
       " 'This',\n",
       " 'is',\n",
       " 'termed',\n",
       " 'tokenizing',\n",
       " 'If',\n",
       " 'the',\n",
       " 'lexer',\n",
       " 'finds',\n",
       " 'an',\n",
       " 'invalid',\n",
       " 'token',\n",
       " 'it',\n",
       " 'will',\n",
       " 'report',\n",
       " 'an',\n",
       " 'error',\n",
       " 'Following',\n",
       " 'tokenizing',\n",
       " 'is',\n",
       " 'parsing',\n",
       " 'From',\n",
       " 'there',\n",
       " 'the',\n",
       " 'interpreted',\n",
       " 'data',\n",
       " 'may',\n",
       " 'be',\n",
       " 'loaded',\n",
       " 'into',\n",
       " 'data',\n",
       " 'structures',\n",
       " 'for',\n",
       " 'general',\n",
       " 'use',\n",
       " 'interpretation',\n",
       " 'or',\n",
       " 'compiling']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\w\\w+\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\b\\w+\\b\",\"a,b,c,d,e,f,g,h,i,j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'The',\n",
       " 'The',\n",
       " 'For',\n",
       " 'The',\n",
       " 'The',\n",
       " 'When',\n",
       " 'The',\n",
       " 'This',\n",
       " 'Tokens',\n",
       " 'Some',\n",
       " 'Special',\n",
       " 'Tokens',\n",
       " 'Categories',\n",
       " 'Categories',\n",
       " 'Programming',\n",
       " 'Written',\n",
       " 'Categories',\n",
       " 'For',\n",
       " 'When',\n",
       " 'For',\n",
       " 'Identifier',\n",
       " 'Assignment',\n",
       " 'Addition',\n",
       " 'Tokens',\n",
       " 'The',\n",
       " 'This',\n",
       " 'If',\n",
       " 'Following',\n",
       " 'From']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\b[A-Z]\\w+\\b\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.findall(r\"\\b\\w\\w+\\b\",text.lower())\n",
    "counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'tokenization': 1,\n",
       "         'is': 7,\n",
       "         'the': 34,\n",
       "         'process': 2,\n",
       "         'of': 14,\n",
       "         'demarcating': 1,\n",
       "         'and': 5,\n",
       "         'possibly': 1,\n",
       "         'classifying': 1,\n",
       "         'sections': 1,\n",
       "         'string': 4,\n",
       "         'input': 3,\n",
       "         'characters': 7,\n",
       "         'resulting': 1,\n",
       "         'tokens': 14,\n",
       "         'are': 8,\n",
       "         'then': 1,\n",
       "         'passed': 1,\n",
       "         'on': 3,\n",
       "         'to': 7,\n",
       "         'some': 2,\n",
       "         'other': 2,\n",
       "         'form': 1,\n",
       "         'processing': 2,\n",
       "         'can': 2,\n",
       "         'be': 5,\n",
       "         'considered': 1,\n",
       "         'sub': 1,\n",
       "         'task': 2,\n",
       "         'parsing': 2,\n",
       "         'for': 6,\n",
       "         'example': 3,\n",
       "         'in': 10,\n",
       "         'text': 1,\n",
       "         'quick': 1,\n",
       "         'brown': 1,\n",
       "         'fox': 1,\n",
       "         'jumps': 1,\n",
       "         'over': 1,\n",
       "         'lazy': 1,\n",
       "         'dog': 1,\n",
       "         'isn': 1,\n",
       "         'implicitly': 1,\n",
       "         'segmented': 1,\n",
       "         'spaces': 1,\n",
       "         'as': 5,\n",
       "         'natural': 2,\n",
       "         'language': 2,\n",
       "         'speaker': 1,\n",
       "         'would': 1,\n",
       "         'do': 1,\n",
       "         'raw': 1,\n",
       "         '43': 1,\n",
       "         'must': 1,\n",
       "         'explicitly': 1,\n",
       "         'split': 1,\n",
       "         'into': 3,\n",
       "         'with': 6,\n",
       "         'given': 1,\n",
       "         'space': 1,\n",
       "         'delimiter': 1,\n",
       "         'matching': 1,\n",
       "         'or': 7,\n",
       "         'regular': 3,\n",
       "         'expression': 1,\n",
       "         'when': 2,\n",
       "         'token': 2,\n",
       "         'class': 1,\n",
       "         'represents': 1,\n",
       "         'more': 1,\n",
       "         'than': 1,\n",
       "         'one': 1,\n",
       "         'possible': 1,\n",
       "         'lexeme': 2,\n",
       "         'lexer': 6,\n",
       "         'often': 5,\n",
       "         'saves': 1,\n",
       "         'enough': 1,\n",
       "         'information': 3,\n",
       "         'reproduce': 1,\n",
       "         'original': 1,\n",
       "         'so': 1,\n",
       "         'that': 2,\n",
       "         'it': 3,\n",
       "         'used': 6,\n",
       "         'semantic': 1,\n",
       "         'analysis': 1,\n",
       "         'parser': 4,\n",
       "         'typically': 2,\n",
       "         'retrieves': 1,\n",
       "         'this': 3,\n",
       "         'from': 2,\n",
       "         'stores': 1,\n",
       "         'abstract': 1,\n",
       "         'syntax': 1,\n",
       "         'tree': 1,\n",
       "         'necessary': 1,\n",
       "         'order': 1,\n",
       "         'avoid': 1,\n",
       "         'loss': 1,\n",
       "         'case': 1,\n",
       "         'where': 1,\n",
       "         'numbers': 1,\n",
       "         'may': 2,\n",
       "         'also': 1,\n",
       "         'valid': 1,\n",
       "         'identifiers': 2,\n",
       "         'identified': 1,\n",
       "         'based': 1,\n",
       "         'specific': 3,\n",
       "         'rules': 2,\n",
       "         'methods': 1,\n",
       "         'identify': 2,\n",
       "         'include': 1,\n",
       "         'expressions': 2,\n",
       "         'sequences': 1,\n",
       "         'termed': 2,\n",
       "         'flag': 1,\n",
       "         'separating': 1,\n",
       "         'called': 1,\n",
       "         'delimiters': 1,\n",
       "         'explicit': 1,\n",
       "         'definition': 1,\n",
       "         'by': 11,\n",
       "         'dictionary': 1,\n",
       "         'special': 1,\n",
       "         'including': 1,\n",
       "         'punctuation': 2,\n",
       "         'commonly': 2,\n",
       "         'lexers': 1,\n",
       "         'because': 1,\n",
       "         'their': 1,\n",
       "         'use': 2,\n",
       "         'written': 2,\n",
       "         'programming': 2,\n",
       "         'languages': 3,\n",
       "         'categorized': 1,\n",
       "         'character': 1,\n",
       "         'content': 1,\n",
       "         'context': 1,\n",
       "         'within': 1,\n",
       "         'data': 5,\n",
       "         'stream': 4,\n",
       "         'categories': 3,\n",
       "         'defined': 2,\n",
       "         'involve': 1,\n",
       "         'grammar': 1,\n",
       "         'elements': 1,\n",
       "         'categorize': 2,\n",
       "         'operators': 1,\n",
       "         'grouping': 1,\n",
       "         'symbols': 1,\n",
       "         'type': 1,\n",
       "         'nouns': 1,\n",
       "         'verbs': 1,\n",
       "         'adjectives': 1,\n",
       "         'post': 1,\n",
       "         'either': 1,\n",
       "         'functions': 1,\n",
       "         'program': 1,\n",
       "         'lexical': 4,\n",
       "         'analyzer': 4,\n",
       "         'generally': 1,\n",
       "         'does': 2,\n",
       "         'nothing': 2,\n",
       "         'combinations': 1,\n",
       "         'left': 1,\n",
       "         'typical': 1,\n",
       "         'recognizes': 1,\n",
       "         'parentheses': 1,\n",
       "         'but': 1,\n",
       "         'ensure': 1,\n",
       "         'each': 1,\n",
       "         'matched': 1,\n",
       "         'feeds': 1,\n",
       "         'representation': 1,\n",
       "         'an': 3,\n",
       "         'enumerated': 1,\n",
       "         'list': 1,\n",
       "         'number': 1,\n",
       "         'representations': 1,\n",
       "         'identifier': 1,\n",
       "         'represented': 1,\n",
       "         'assignment': 1,\n",
       "         'operator': 2,\n",
       "         'addition': 1,\n",
       "         'etc': 1,\n",
       "         'which': 1,\n",
       "         'understood': 1,\n",
       "         'generator': 1,\n",
       "         'such': 1,\n",
       "         'lex': 2,\n",
       "         'generated': 1,\n",
       "         'automatically': 1,\n",
       "         'tool': 1,\n",
       "         'like': 1,\n",
       "         'hand': 1,\n",
       "         'crafted': 1,\n",
       "         'reads': 1,\n",
       "         'identifies': 1,\n",
       "         'lexemes': 1,\n",
       "         'categorizes': 1,\n",
       "         'them': 1,\n",
       "         'tokenizing': 2,\n",
       "         'if': 1,\n",
       "         'finds': 1,\n",
       "         'invalid': 1,\n",
       "         'will': 1,\n",
       "         'report': 1,\n",
       "         'error': 1,\n",
       "         'following': 1,\n",
       "         'there': 1,\n",
       "         'interpreted': 1,\n",
       "         'loaded': 1,\n",
       "         'structures': 1,\n",
       "         'general': 1,\n",
       "         'interpretation': 1,\n",
       "         'compiling': 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['43',\n",
       " 'abstract',\n",
       " 'addition',\n",
       " 'adjectives',\n",
       " 'also',\n",
       " 'an',\n",
       " 'analysis',\n",
       " 'analyzer',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'assignment',\n",
       " 'automatically',\n",
       " 'avoid',\n",
       " 'based',\n",
       " 'be',\n",
       " 'because',\n",
       " 'brown',\n",
       " 'but',\n",
       " 'by',\n",
       " 'called',\n",
       " 'can',\n",
       " 'case',\n",
       " 'categories',\n",
       " 'categorize',\n",
       " 'categorized',\n",
       " 'categorizes',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'class',\n",
       " 'classifying',\n",
       " 'combinations',\n",
       " 'commonly',\n",
       " 'compiling',\n",
       " 'considered',\n",
       " 'content',\n",
       " 'context',\n",
       " 'crafted',\n",
       " 'data',\n",
       " 'defined',\n",
       " 'definition',\n",
       " 'delimiter',\n",
       " 'delimiters',\n",
       " 'demarcating',\n",
       " 'dictionary',\n",
       " 'do',\n",
       " 'does',\n",
       " 'dog',\n",
       " 'each',\n",
       " 'either',\n",
       " 'elements',\n",
       " 'enough',\n",
       " 'ensure',\n",
       " 'enumerated',\n",
       " 'error',\n",
       " 'etc',\n",
       " 'example',\n",
       " 'explicit',\n",
       " 'explicitly',\n",
       " 'expression',\n",
       " 'expressions',\n",
       " 'feeds',\n",
       " 'finds',\n",
       " 'flag',\n",
       " 'following',\n",
       " 'for',\n",
       " 'form',\n",
       " 'fox',\n",
       " 'from',\n",
       " 'functions',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generated',\n",
       " 'generator',\n",
       " 'given',\n",
       " 'grammar',\n",
       " 'grouping',\n",
       " 'hand',\n",
       " 'identified',\n",
       " 'identifier',\n",
       " 'identifiers',\n",
       " 'identifies',\n",
       " 'identify',\n",
       " 'if',\n",
       " 'implicitly',\n",
       " 'in',\n",
       " 'include',\n",
       " 'including',\n",
       " 'information',\n",
       " 'input',\n",
       " 'interpretation',\n",
       " 'interpreted',\n",
       " 'into',\n",
       " 'invalid',\n",
       " 'involve',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'jumps',\n",
       " 'language',\n",
       " 'languages',\n",
       " 'lazy',\n",
       " 'left',\n",
       " 'lex',\n",
       " 'lexeme',\n",
       " 'lexemes',\n",
       " 'lexer',\n",
       " 'lexers',\n",
       " 'lexical',\n",
       " 'like',\n",
       " 'list',\n",
       " 'loaded',\n",
       " 'loss',\n",
       " 'matched',\n",
       " 'matching',\n",
       " 'may',\n",
       " 'methods',\n",
       " 'more',\n",
       " 'must',\n",
       " 'natural',\n",
       " 'necessary',\n",
       " 'nothing',\n",
       " 'nouns',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'of',\n",
       " 'often',\n",
       " 'on',\n",
       " 'one',\n",
       " 'operator',\n",
       " 'operators',\n",
       " 'or',\n",
       " 'order',\n",
       " 'original',\n",
       " 'other',\n",
       " 'over',\n",
       " 'parentheses',\n",
       " 'parser',\n",
       " 'parsing',\n",
       " 'passed',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'post',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'program',\n",
       " 'programming',\n",
       " 'punctuation',\n",
       " 'quick',\n",
       " 'raw',\n",
       " 'reads',\n",
       " 'recognizes',\n",
       " 'regular',\n",
       " 'report',\n",
       " 'representation',\n",
       " 'representations',\n",
       " 'represented',\n",
       " 'represents',\n",
       " 'reproduce',\n",
       " 'resulting',\n",
       " 'retrieves',\n",
       " 'rules',\n",
       " 'saves',\n",
       " 'sections',\n",
       " 'segmented',\n",
       " 'semantic',\n",
       " 'separating',\n",
       " 'sequences',\n",
       " 'so',\n",
       " 'some',\n",
       " 'space',\n",
       " 'spaces',\n",
       " 'speaker',\n",
       " 'special',\n",
       " 'specific',\n",
       " 'split',\n",
       " 'stores',\n",
       " 'stream',\n",
       " 'string',\n",
       " 'structures',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'symbols',\n",
       " 'syntax',\n",
       " 'task',\n",
       " 'termed',\n",
       " 'text',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'this',\n",
       " 'to',\n",
       " 'token',\n",
       " 'tokenization',\n",
       " 'tokenizing',\n",
       " 'tokens',\n",
       " 'tool',\n",
       " 'tree',\n",
       " 'type',\n",
       " 'typical',\n",
       " 'typically',\n",
       " 'understood',\n",
       " 'use',\n",
       " 'used',\n",
       " 'valid',\n",
       " 'verbs',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'would',\n",
       " 'written']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['written',\n",
       " 'would',\n",
       " 'within',\n",
       " 'with',\n",
       " 'will',\n",
       " 'which',\n",
       " 'where',\n",
       " 'when',\n",
       " 'verbs',\n",
       " 'valid',\n",
       " 'used',\n",
       " 'use',\n",
       " 'understood',\n",
       " 'typically',\n",
       " 'typical',\n",
       " 'type',\n",
       " 'tree',\n",
       " 'tool',\n",
       " 'tokens',\n",
       " 'tokenizing',\n",
       " 'tokenization',\n",
       " 'token',\n",
       " 'to',\n",
       " 'this',\n",
       " 'there',\n",
       " 'then',\n",
       " 'them',\n",
       " 'their',\n",
       " 'the',\n",
       " 'that',\n",
       " 'than',\n",
       " 'text',\n",
       " 'termed',\n",
       " 'task',\n",
       " 'syntax',\n",
       " 'symbols',\n",
       " 'such',\n",
       " 'sub',\n",
       " 'structures',\n",
       " 'string',\n",
       " 'stream',\n",
       " 'stores',\n",
       " 'split',\n",
       " 'specific',\n",
       " 'special',\n",
       " 'speaker',\n",
       " 'spaces',\n",
       " 'space',\n",
       " 'some',\n",
       " 'so',\n",
       " 'sequences',\n",
       " 'separating',\n",
       " 'semantic',\n",
       " 'segmented',\n",
       " 'sections',\n",
       " 'saves',\n",
       " 'rules',\n",
       " 'retrieves',\n",
       " 'resulting',\n",
       " 'reproduce',\n",
       " 'represents',\n",
       " 'represented',\n",
       " 'representations',\n",
       " 'representation',\n",
       " 'report',\n",
       " 'regular',\n",
       " 'recognizes',\n",
       " 'reads',\n",
       " 'raw',\n",
       " 'quick',\n",
       " 'punctuation',\n",
       " 'programming',\n",
       " 'program',\n",
       " 'processing',\n",
       " 'process',\n",
       " 'post',\n",
       " 'possibly',\n",
       " 'possible',\n",
       " 'passed',\n",
       " 'parsing',\n",
       " 'parser',\n",
       " 'parentheses',\n",
       " 'over',\n",
       " 'other',\n",
       " 'original',\n",
       " 'order',\n",
       " 'or',\n",
       " 'operators',\n",
       " 'operator',\n",
       " 'one',\n",
       " 'on',\n",
       " 'often',\n",
       " 'of',\n",
       " 'numbers',\n",
       " 'number',\n",
       " 'nouns',\n",
       " 'nothing',\n",
       " 'necessary',\n",
       " 'natural',\n",
       " 'must',\n",
       " 'more',\n",
       " 'methods',\n",
       " 'may',\n",
       " 'matching',\n",
       " 'matched',\n",
       " 'loss',\n",
       " 'loaded',\n",
       " 'list',\n",
       " 'like',\n",
       " 'lexical',\n",
       " 'lexers',\n",
       " 'lexer',\n",
       " 'lexemes',\n",
       " 'lexeme',\n",
       " 'lex',\n",
       " 'left',\n",
       " 'lazy',\n",
       " 'languages',\n",
       " 'language',\n",
       " 'jumps',\n",
       " 'it',\n",
       " 'isn',\n",
       " 'is',\n",
       " 'involve',\n",
       " 'invalid',\n",
       " 'into',\n",
       " 'interpreted',\n",
       " 'interpretation',\n",
       " 'input',\n",
       " 'information',\n",
       " 'including',\n",
       " 'include',\n",
       " 'in',\n",
       " 'implicitly',\n",
       " 'if',\n",
       " 'identify',\n",
       " 'identifies',\n",
       " 'identifiers',\n",
       " 'identifier',\n",
       " 'identified',\n",
       " 'hand',\n",
       " 'grouping',\n",
       " 'grammar',\n",
       " 'given',\n",
       " 'generator',\n",
       " 'generated',\n",
       " 'generally',\n",
       " 'general',\n",
       " 'functions',\n",
       " 'from',\n",
       " 'fox',\n",
       " 'form',\n",
       " 'for',\n",
       " 'following',\n",
       " 'flag',\n",
       " 'finds',\n",
       " 'feeds',\n",
       " 'expressions',\n",
       " 'expression',\n",
       " 'explicitly',\n",
       " 'explicit',\n",
       " 'example',\n",
       " 'etc',\n",
       " 'error',\n",
       " 'enumerated',\n",
       " 'ensure',\n",
       " 'enough',\n",
       " 'elements',\n",
       " 'either',\n",
       " 'each',\n",
       " 'dog',\n",
       " 'does',\n",
       " 'do',\n",
       " 'dictionary',\n",
       " 'demarcating',\n",
       " 'delimiters',\n",
       " 'delimiter',\n",
       " 'definition',\n",
       " 'defined',\n",
       " 'data',\n",
       " 'crafted',\n",
       " 'context',\n",
       " 'content',\n",
       " 'considered',\n",
       " 'compiling',\n",
       " 'commonly',\n",
       " 'combinations',\n",
       " 'classifying',\n",
       " 'class',\n",
       " 'characters',\n",
       " 'character',\n",
       " 'categorizes',\n",
       " 'categorized',\n",
       " 'categorize',\n",
       " 'categories',\n",
       " 'case',\n",
       " 'can',\n",
       " 'called',\n",
       " 'by',\n",
       " 'but',\n",
       " 'brown',\n",
       " 'because',\n",
       " 'be',\n",
       " 'based',\n",
       " 'avoid',\n",
       " 'automatically',\n",
       " 'assignment',\n",
       " 'as',\n",
       " 'are',\n",
       " 'and',\n",
       " 'analyzer',\n",
       " 'analysis',\n",
       " 'an',\n",
       " 'also',\n",
       " 'adjectives',\n",
       " 'addition',\n",
       " 'abstract',\n",
       " '43']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['43',\n",
       " 'abstract',\n",
       " 'addition',\n",
       " 'adjectives',\n",
       " 'also',\n",
       " 'an',\n",
       " 'analysis',\n",
       " 'analyzer',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'assignment',\n",
       " 'automatically',\n",
       " 'avoid',\n",
       " 'based',\n",
       " 'be',\n",
       " 'because',\n",
       " 'brown',\n",
       " 'but',\n",
       " 'by',\n",
       " 'called',\n",
       " 'can',\n",
       " 'case',\n",
       " 'categories',\n",
       " 'categorize',\n",
       " 'categorized',\n",
       " 'categorizes',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'class',\n",
       " 'classifying',\n",
       " 'combinations',\n",
       " 'commonly',\n",
       " 'compiling',\n",
       " 'considered',\n",
       " 'content',\n",
       " 'context',\n",
       " 'crafted',\n",
       " 'data',\n",
       " 'defined',\n",
       " 'definition',\n",
       " 'delimiter',\n",
       " 'delimiters',\n",
       " 'demarcating',\n",
       " 'dictionary',\n",
       " 'do',\n",
       " 'does',\n",
       " 'dog',\n",
       " 'each',\n",
       " 'either',\n",
       " 'elements',\n",
       " 'enough',\n",
       " 'ensure',\n",
       " 'enumerated',\n",
       " 'error',\n",
       " 'etc',\n",
       " 'example',\n",
       " 'explicit',\n",
       " 'explicitly',\n",
       " 'expression',\n",
       " 'expressions',\n",
       " 'feeds',\n",
       " 'finds',\n",
       " 'flag',\n",
       " 'following',\n",
       " 'for',\n",
       " 'form',\n",
       " 'fox',\n",
       " 'from',\n",
       " 'functions',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generated',\n",
       " 'generator',\n",
       " 'given',\n",
       " 'grammar',\n",
       " 'grouping',\n",
       " 'hand',\n",
       " 'identified',\n",
       " 'identifier',\n",
       " 'identifiers',\n",
       " 'identifies',\n",
       " 'identify',\n",
       " 'if',\n",
       " 'implicitly',\n",
       " 'in',\n",
       " 'include',\n",
       " 'including',\n",
       " 'information',\n",
       " 'input',\n",
       " 'interpretation',\n",
       " 'interpreted',\n",
       " 'into',\n",
       " 'invalid',\n",
       " 'involve',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'jumps',\n",
       " 'language',\n",
       " 'languages',\n",
       " 'lazy',\n",
       " 'left',\n",
       " 'lex',\n",
       " 'lexeme',\n",
       " 'lexemes',\n",
       " 'lexer',\n",
       " 'lexers',\n",
       " 'lexical',\n",
       " 'like',\n",
       " 'list',\n",
       " 'loaded',\n",
       " 'loss',\n",
       " 'matched',\n",
       " 'matching',\n",
       " 'may',\n",
       " 'methods',\n",
       " 'more',\n",
       " 'must',\n",
       " 'natural',\n",
       " 'necessary',\n",
       " 'nothing',\n",
       " 'nouns',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'of',\n",
       " 'often',\n",
       " 'on',\n",
       " 'one',\n",
       " 'operator',\n",
       " 'operators',\n",
       " 'or',\n",
       " 'order',\n",
       " 'original',\n",
       " 'other',\n",
       " 'over',\n",
       " 'parentheses',\n",
       " 'parser',\n",
       " 'parsing',\n",
       " 'passed',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'post',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'program',\n",
       " 'programming',\n",
       " 'punctuation',\n",
       " 'quick',\n",
       " 'raw',\n",
       " 'reads',\n",
       " 'recognizes',\n",
       " 'regular',\n",
       " 'report',\n",
       " 'representation',\n",
       " 'representations',\n",
       " 'represented',\n",
       " 'represents',\n",
       " 'reproduce',\n",
       " 'resulting',\n",
       " 'retrieves',\n",
       " 'rules',\n",
       " 'saves',\n",
       " 'sections',\n",
       " 'segmented',\n",
       " 'semantic',\n",
       " 'separating',\n",
       " 'sequences',\n",
       " 'so',\n",
       " 'some',\n",
       " 'space',\n",
       " 'spaces',\n",
       " 'speaker',\n",
       " 'special',\n",
       " 'specific',\n",
       " 'split',\n",
       " 'stores',\n",
       " 'stream',\n",
       " 'string',\n",
       " 'structures',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'symbols',\n",
       " 'syntax',\n",
       " 'task',\n",
       " 'termed',\n",
       " 'text',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'this',\n",
       " 'to',\n",
       " 'token',\n",
       " 'tokenization',\n",
       " 'tokenizing',\n",
       " 'tokens',\n",
       " 'tool',\n",
       " 'tree',\n",
       " 'type',\n",
       " 'typical',\n",
       " 'typically',\n",
       " 'understood',\n",
       " 'use',\n",
       " 'used',\n",
       " 'valid',\n",
       " 'verbs',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'would',\n",
       " 'written']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=list(counts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('43', 1),\n",
       " ('abstract', 1),\n",
       " ('addition', 1),\n",
       " ('adjectives', 1),\n",
       " ('also', 1),\n",
       " ('an', 3),\n",
       " ('analysis', 1),\n",
       " ('analyzer', 4),\n",
       " ('and', 5),\n",
       " ('are', 8),\n",
       " ('as', 5),\n",
       " ('assignment', 1),\n",
       " ('automatically', 1),\n",
       " ('avoid', 1),\n",
       " ('based', 1),\n",
       " ('be', 5),\n",
       " ('because', 1),\n",
       " ('brown', 1),\n",
       " ('but', 1),\n",
       " ('by', 11),\n",
       " ('called', 1),\n",
       " ('can', 2),\n",
       " ('case', 1),\n",
       " ('categories', 3),\n",
       " ('categorize', 2),\n",
       " ('categorized', 1),\n",
       " ('categorizes', 1),\n",
       " ('character', 1),\n",
       " ('characters', 7),\n",
       " ('class', 1),\n",
       " ('classifying', 1),\n",
       " ('combinations', 1),\n",
       " ('commonly', 2),\n",
       " ('compiling', 1),\n",
       " ('considered', 1),\n",
       " ('content', 1),\n",
       " ('context', 1),\n",
       " ('crafted', 1),\n",
       " ('data', 5),\n",
       " ('defined', 2),\n",
       " ('definition', 1),\n",
       " ('delimiter', 1),\n",
       " ('delimiters', 1),\n",
       " ('demarcating', 1),\n",
       " ('dictionary', 1),\n",
       " ('do', 1),\n",
       " ('does', 2),\n",
       " ('dog', 1),\n",
       " ('each', 1),\n",
       " ('either', 1),\n",
       " ('elements', 1),\n",
       " ('enough', 1),\n",
       " ('ensure', 1),\n",
       " ('enumerated', 1),\n",
       " ('error', 1),\n",
       " ('etc', 1),\n",
       " ('example', 3),\n",
       " ('explicit', 1),\n",
       " ('explicitly', 1),\n",
       " ('expression', 1),\n",
       " ('expressions', 2),\n",
       " ('feeds', 1),\n",
       " ('finds', 1),\n",
       " ('flag', 1),\n",
       " ('following', 1),\n",
       " ('for', 6),\n",
       " ('form', 1),\n",
       " ('fox', 1),\n",
       " ('from', 2),\n",
       " ('functions', 1),\n",
       " ('general', 1),\n",
       " ('generally', 1),\n",
       " ('generated', 1),\n",
       " ('generator', 1),\n",
       " ('given', 1),\n",
       " ('grammar', 1),\n",
       " ('grouping', 1),\n",
       " ('hand', 1),\n",
       " ('identified', 1),\n",
       " ('identifier', 1),\n",
       " ('identifiers', 2),\n",
       " ('identifies', 1),\n",
       " ('identify', 2),\n",
       " ('if', 1),\n",
       " ('implicitly', 1),\n",
       " ('in', 10),\n",
       " ('include', 1),\n",
       " ('including', 1),\n",
       " ('information', 3),\n",
       " ('input', 3),\n",
       " ('interpretation', 1),\n",
       " ('interpreted', 1),\n",
       " ('into', 3),\n",
       " ('invalid', 1),\n",
       " ('involve', 1),\n",
       " ('is', 7),\n",
       " ('isn', 1),\n",
       " ('it', 3),\n",
       " ('jumps', 1),\n",
       " ('language', 2),\n",
       " ('languages', 3),\n",
       " ('lazy', 1),\n",
       " ('left', 1),\n",
       " ('lex', 2),\n",
       " ('lexeme', 2),\n",
       " ('lexemes', 1),\n",
       " ('lexer', 6),\n",
       " ('lexers', 1),\n",
       " ('lexical', 4),\n",
       " ('like', 1),\n",
       " ('list', 1),\n",
       " ('loaded', 1),\n",
       " ('loss', 1),\n",
       " ('matched', 1),\n",
       " ('matching', 1),\n",
       " ('may', 2),\n",
       " ('methods', 1),\n",
       " ('more', 1),\n",
       " ('must', 1),\n",
       " ('natural', 2),\n",
       " ('necessary', 1),\n",
       " ('nothing', 2),\n",
       " ('nouns', 1),\n",
       " ('number', 1),\n",
       " ('numbers', 1),\n",
       " ('of', 14),\n",
       " ('often', 5),\n",
       " ('on', 3),\n",
       " ('one', 1),\n",
       " ('operator', 2),\n",
       " ('operators', 1),\n",
       " ('or', 7),\n",
       " ('order', 1),\n",
       " ('original', 1),\n",
       " ('other', 2),\n",
       " ('over', 1),\n",
       " ('parentheses', 1),\n",
       " ('parser', 4),\n",
       " ('parsing', 2),\n",
       " ('passed', 1),\n",
       " ('possible', 1),\n",
       " ('possibly', 1),\n",
       " ('post', 1),\n",
       " ('process', 2),\n",
       " ('processing', 2),\n",
       " ('program', 1),\n",
       " ('programming', 2),\n",
       " ('punctuation', 2),\n",
       " ('quick', 1),\n",
       " ('raw', 1),\n",
       " ('reads', 1),\n",
       " ('recognizes', 1),\n",
       " ('regular', 3),\n",
       " ('report', 1),\n",
       " ('representation', 1),\n",
       " ('representations', 1),\n",
       " ('represented', 1),\n",
       " ('represents', 1),\n",
       " ('reproduce', 1),\n",
       " ('resulting', 1),\n",
       " ('retrieves', 1),\n",
       " ('rules', 2),\n",
       " ('saves', 1),\n",
       " ('sections', 1),\n",
       " ('segmented', 1),\n",
       " ('semantic', 1),\n",
       " ('separating', 1),\n",
       " ('sequences', 1),\n",
       " ('so', 1),\n",
       " ('some', 2),\n",
       " ('space', 1),\n",
       " ('spaces', 1),\n",
       " ('speaker', 1),\n",
       " ('special', 1),\n",
       " ('specific', 3),\n",
       " ('split', 1),\n",
       " ('stores', 1),\n",
       " ('stream', 4),\n",
       " ('string', 4),\n",
       " ('structures', 1),\n",
       " ('sub', 1),\n",
       " ('such', 1),\n",
       " ('symbols', 1),\n",
       " ('syntax', 1),\n",
       " ('task', 2),\n",
       " ('termed', 2),\n",
       " ('text', 1),\n",
       " ('than', 1),\n",
       " ('that', 2),\n",
       " ('the', 34),\n",
       " ('their', 1),\n",
       " ('them', 1),\n",
       " ('then', 1),\n",
       " ('there', 1),\n",
       " ('this', 3),\n",
       " ('to', 7),\n",
       " ('token', 2),\n",
       " ('tokenization', 1),\n",
       " ('tokenizing', 2),\n",
       " ('tokens', 14),\n",
       " ('tool', 1),\n",
       " ('tree', 1),\n",
       " ('type', 1),\n",
       " ('typical', 1),\n",
       " ('typically', 2),\n",
       " ('understood', 1),\n",
       " ('use', 2),\n",
       " ('used', 6),\n",
       " ('valid', 1),\n",
       " ('verbs', 1),\n",
       " ('when', 2),\n",
       " ('where', 1),\n",
       " ('which', 1),\n",
       " ('will', 1),\n",
       " ('with', 6),\n",
       " ('within', 1),\n",
       " ('would', 1),\n",
       " ('written', 2)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'43': 1,\n",
       " 'abstract': 1,\n",
       " 'addition': 1,\n",
       " 'adjectives': 1,\n",
       " 'also': 1,\n",
       " 'an': 3,\n",
       " 'analysis': 1,\n",
       " 'analyzer': 4,\n",
       " 'and': 5,\n",
       " 'are': 8,\n",
       " 'as': 5,\n",
       " 'assignment': 1,\n",
       " 'automatically': 1,\n",
       " 'avoid': 1,\n",
       " 'based': 1,\n",
       " 'be': 5,\n",
       " 'because': 1,\n",
       " 'brown': 1,\n",
       " 'but': 1,\n",
       " 'by': 11,\n",
       " 'called': 1,\n",
       " 'can': 2,\n",
       " 'case': 1,\n",
       " 'categories': 3,\n",
       " 'categorize': 2,\n",
       " 'categorized': 1,\n",
       " 'categorizes': 1,\n",
       " 'character': 1,\n",
       " 'characters': 7,\n",
       " 'class': 1,\n",
       " 'classifying': 1,\n",
       " 'combinations': 1,\n",
       " 'commonly': 2,\n",
       " 'compiling': 1,\n",
       " 'considered': 1,\n",
       " 'content': 1,\n",
       " 'context': 1,\n",
       " 'crafted': 1,\n",
       " 'data': 5,\n",
       " 'defined': 2,\n",
       " 'definition': 1,\n",
       " 'delimiter': 1,\n",
       " 'delimiters': 1,\n",
       " 'demarcating': 1,\n",
       " 'dictionary': 1,\n",
       " 'do': 1,\n",
       " 'does': 2,\n",
       " 'dog': 1,\n",
       " 'each': 1,\n",
       " 'either': 1,\n",
       " 'elements': 1,\n",
       " 'enough': 1,\n",
       " 'ensure': 1,\n",
       " 'enumerated': 1,\n",
       " 'error': 1,\n",
       " 'etc': 1,\n",
       " 'example': 3,\n",
       " 'explicit': 1,\n",
       " 'explicitly': 1,\n",
       " 'expression': 1,\n",
       " 'expressions': 2,\n",
       " 'feeds': 1,\n",
       " 'finds': 1,\n",
       " 'flag': 1,\n",
       " 'following': 1,\n",
       " 'for': 6,\n",
       " 'form': 1,\n",
       " 'fox': 1,\n",
       " 'from': 2,\n",
       " 'functions': 1,\n",
       " 'general': 1,\n",
       " 'generally': 1,\n",
       " 'generated': 1,\n",
       " 'generator': 1,\n",
       " 'given': 1,\n",
       " 'grammar': 1,\n",
       " 'grouping': 1,\n",
       " 'hand': 1,\n",
       " 'identified': 1,\n",
       " 'identifier': 1,\n",
       " 'identifiers': 2,\n",
       " 'identifies': 1,\n",
       " 'identify': 2,\n",
       " 'if': 1,\n",
       " 'implicitly': 1,\n",
       " 'in': 10,\n",
       " 'include': 1,\n",
       " 'including': 1,\n",
       " 'information': 3,\n",
       " 'input': 3,\n",
       " 'interpretation': 1,\n",
       " 'interpreted': 1,\n",
       " 'into': 3,\n",
       " 'invalid': 1,\n",
       " 'involve': 1,\n",
       " 'is': 7,\n",
       " 'isn': 1,\n",
       " 'it': 3,\n",
       " 'jumps': 1,\n",
       " 'language': 2,\n",
       " 'languages': 3,\n",
       " 'lazy': 1,\n",
       " 'left': 1,\n",
       " 'lex': 2,\n",
       " 'lexeme': 2,\n",
       " 'lexemes': 1,\n",
       " 'lexer': 6,\n",
       " 'lexers': 1,\n",
       " 'lexical': 4,\n",
       " 'like': 1,\n",
       " 'list': 1,\n",
       " 'loaded': 1,\n",
       " 'loss': 1,\n",
       " 'matched': 1,\n",
       " 'matching': 1,\n",
       " 'may': 2,\n",
       " 'methods': 1,\n",
       " 'more': 1,\n",
       " 'must': 1,\n",
       " 'natural': 2,\n",
       " 'necessary': 1,\n",
       " 'nothing': 2,\n",
       " 'nouns': 1,\n",
       " 'number': 1,\n",
       " 'numbers': 1,\n",
       " 'of': 14,\n",
       " 'often': 5,\n",
       " 'on': 3,\n",
       " 'one': 1,\n",
       " 'operator': 2,\n",
       " 'operators': 1,\n",
       " 'or': 7,\n",
       " 'order': 1,\n",
       " 'original': 1,\n",
       " 'other': 2,\n",
       " 'over': 1,\n",
       " 'parentheses': 1,\n",
       " 'parser': 4,\n",
       " 'parsing': 2,\n",
       " 'passed': 1,\n",
       " 'possible': 1,\n",
       " 'possibly': 1,\n",
       " 'post': 1,\n",
       " 'process': 2,\n",
       " 'processing': 2,\n",
       " 'program': 1,\n",
       " 'programming': 2,\n",
       " 'punctuation': 2,\n",
       " 'quick': 1,\n",
       " 'raw': 1,\n",
       " 'reads': 1,\n",
       " 'recognizes': 1,\n",
       " 'regular': 3,\n",
       " 'report': 1,\n",
       " 'representation': 1,\n",
       " 'representations': 1,\n",
       " 'represented': 1,\n",
       " 'represents': 1,\n",
       " 'reproduce': 1,\n",
       " 'resulting': 1,\n",
       " 'retrieves': 1,\n",
       " 'rules': 2,\n",
       " 'saves': 1,\n",
       " 'sections': 1,\n",
       " 'segmented': 1,\n",
       " 'semantic': 1,\n",
       " 'separating': 1,\n",
       " 'sequences': 1,\n",
       " 'so': 1,\n",
       " 'some': 2,\n",
       " 'space': 1,\n",
       " 'spaces': 1,\n",
       " 'speaker': 1,\n",
       " 'special': 1,\n",
       " 'specific': 3,\n",
       " 'split': 1,\n",
       " 'stores': 1,\n",
       " 'stream': 4,\n",
       " 'string': 4,\n",
       " 'structures': 1,\n",
       " 'sub': 1,\n",
       " 'such': 1,\n",
       " 'symbols': 1,\n",
       " 'syntax': 1,\n",
       " 'task': 2,\n",
       " 'termed': 2,\n",
       " 'text': 1,\n",
       " 'than': 1,\n",
       " 'that': 2,\n",
       " 'the': 34,\n",
       " 'their': 1,\n",
       " 'them': 1,\n",
       " 'then': 1,\n",
       " 'there': 1,\n",
       " 'this': 3,\n",
       " 'to': 7,\n",
       " 'token': 2,\n",
       " 'tokenization': 1,\n",
       " 'tokenizing': 2,\n",
       " 'tokens': 14,\n",
       " 'tool': 1,\n",
       " 'tree': 1,\n",
       " 'type': 1,\n",
       " 'typical': 1,\n",
       " 'typically': 2,\n",
       " 'understood': 1,\n",
       " 'use': 2,\n",
       " 'used': 6,\n",
       " 'valid': 1,\n",
       " 'verbs': 1,\n",
       " 'when': 2,\n",
       " 'where': 1,\n",
       " 'which': 1,\n",
       " 'will': 1,\n",
       " 'with': 6,\n",
       " 'within': 1,\n",
       " 'would': 1,\n",
       " 'written': 2}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_counts=dict(sorted(counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('tokenization', 1), ('is', 7), ('the', 34), ('process', 2), ('of', 14), ('demarcating', 1), ('and', 5), ('possibly', 1), ('classifying', 1), ('sections', 1), ('string', 4), ('input', 3), ('characters', 7), ('resulting', 1), ('tokens', 14), ('are', 8), ('then', 1), ('passed', 1), ('on', 3), ('to', 7), ('some', 2), ('other', 2), ('form', 1), ('processing', 2), ('can', 2), ('be', 5), ('considered', 1), ('sub', 1), ('task', 2), ('parsing', 2), ('for', 6), ('example', 3), ('in', 10), ('text', 1), ('quick', 1), ('brown', 1), ('fox', 1), ('jumps', 1), ('over', 1), ('lazy', 1), ('dog', 1), ('isn', 1), ('implicitly', 1), ('segmented', 1), ('spaces', 1), ('as', 5), ('natural', 2), ('language', 2), ('speaker', 1), ('would', 1), ('do', 1), ('raw', 1), ('43', 1), ('must', 1), ('explicitly', 1), ('split', 1), ('into', 3), ('with', 6), ('given', 1), ('space', 1), ('delimiter', 1), ('matching', 1), ('or', 7), ('regular', 3), ('expression', 1), ('when', 2), ('token', 2), ('class', 1), ('represents', 1), ('more', 1), ('than', 1), ('one', 1), ('possible', 1), ('lexeme', 2), ('lexer', 6), ('often', 5), ('saves', 1), ('enough', 1), ('information', 3), ('reproduce', 1), ('original', 1), ('so', 1), ('that', 2), ('it', 3), ('used', 6), ('semantic', 1), ('analysis', 1), ('parser', 4), ('typically', 2), ('retrieves', 1), ('this', 3), ('from', 2), ('stores', 1), ('abstract', 1), ('syntax', 1), ('tree', 1), ('necessary', 1), ('order', 1), ('avoid', 1), ('loss', 1), ('case', 1), ('where', 1), ('numbers', 1), ('may', 2), ('also', 1), ('valid', 1), ('identifiers', 2), ('identified', 1), ('based', 1), ('specific', 3), ('rules', 2), ('methods', 1), ('identify', 2), ('include', 1), ('expressions', 2), ('sequences', 1), ('termed', 2), ('flag', 1), ('separating', 1), ('called', 1), ('delimiters', 1), ('explicit', 1), ('definition', 1), ('by', 11), ('dictionary', 1), ('special', 1), ('including', 1), ('punctuation', 2), ('commonly', 2), ('lexers', 1), ('because', 1), ('their', 1), ('use', 2), ('written', 2), ('programming', 2), ('languages', 3), ('categorized', 1), ('character', 1), ('content', 1), ('context', 1), ('within', 1), ('data', 5), ('stream', 4), ('categories', 3), ('defined', 2), ('involve', 1), ('grammar', 1), ('elements', 1), ('categorize', 2), ('operators', 1), ('grouping', 1), ('symbols', 1), ('type', 1), ('nouns', 1), ('verbs', 1), ('adjectives', 1), ('post', 1), ('either', 1), ('functions', 1), ('program', 1), ('lexical', 4), ('analyzer', 4), ('generally', 1), ('does', 2), ('nothing', 2), ('combinations', 1), ('left', 1), ('typical', 1), ('recognizes', 1), ('parentheses', 1), ('but', 1), ('ensure', 1), ('each', 1), ('matched', 1), ('feeds', 1), ('representation', 1), ('an', 3), ('enumerated', 1), ('list', 1), ('number', 1), ('representations', 1), ('identifier', 1), ('represented', 1), ('assignment', 1), ('operator', 2), ('addition', 1), ('etc', 1), ('which', 1), ('understood', 1), ('generator', 1), ('such', 1), ('lex', 2), ('generated', 1), ('automatically', 1), ('tool', 1), ('like', 1), ('hand', 1), ('crafted', 1), ('reads', 1), ('identifies', 1), ('lexemes', 1), ('categorizes', 1), ('them', 1), ('tokenizing', 2), ('if', 1), ('finds', 1), ('invalid', 1), ('will', 1), ('report', 1), ('error', 1), ('following', 1), ('there', 1), ('interpreted', 1), ('loaded', 1), ('structures', 1), ('general', 1), ('interpretation', 1), ('compiling', 1)])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second(x):\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 34),\n",
       " ('of', 14),\n",
       " ('tokens', 14),\n",
       " ('by', 11),\n",
       " ('in', 10),\n",
       " ('are', 8),\n",
       " ('is', 7),\n",
       " ('characters', 7),\n",
       " ('to', 7),\n",
       " ('or', 7),\n",
       " ('for', 6),\n",
       " ('with', 6),\n",
       " ('lexer', 6),\n",
       " ('used', 6),\n",
       " ('and', 5),\n",
       " ('be', 5),\n",
       " ('as', 5),\n",
       " ('often', 5),\n",
       " ('data', 5),\n",
       " ('string', 4),\n",
       " ('parser', 4),\n",
       " ('stream', 4),\n",
       " ('lexical', 4),\n",
       " ('analyzer', 4),\n",
       " ('input', 3),\n",
       " ('on', 3),\n",
       " ('example', 3),\n",
       " ('into', 3),\n",
       " ('regular', 3),\n",
       " ('information', 3),\n",
       " ('it', 3),\n",
       " ('this', 3),\n",
       " ('specific', 3),\n",
       " ('languages', 3),\n",
       " ('categories', 3),\n",
       " ('an', 3),\n",
       " ('process', 2),\n",
       " ('some', 2),\n",
       " ('other', 2),\n",
       " ('processing', 2),\n",
       " ('can', 2),\n",
       " ('task', 2),\n",
       " ('parsing', 2),\n",
       " ('natural', 2),\n",
       " ('language', 2),\n",
       " ('when', 2),\n",
       " ('token', 2),\n",
       " ('lexeme', 2),\n",
       " ('that', 2),\n",
       " ('typically', 2),\n",
       " ('from', 2),\n",
       " ('may', 2),\n",
       " ('identifiers', 2),\n",
       " ('rules', 2),\n",
       " ('identify', 2),\n",
       " ('expressions', 2),\n",
       " ('termed', 2),\n",
       " ('punctuation', 2),\n",
       " ('commonly', 2),\n",
       " ('use', 2),\n",
       " ('written', 2),\n",
       " ('programming', 2),\n",
       " ('defined', 2),\n",
       " ('categorize', 2),\n",
       " ('does', 2),\n",
       " ('nothing', 2),\n",
       " ('operator', 2),\n",
       " ('lex', 2),\n",
       " ('tokenizing', 2),\n",
       " ('tokenization', 1),\n",
       " ('demarcating', 1),\n",
       " ('possibly', 1),\n",
       " ('classifying', 1),\n",
       " ('sections', 1),\n",
       " ('resulting', 1),\n",
       " ('then', 1),\n",
       " ('passed', 1),\n",
       " ('form', 1),\n",
       " ('considered', 1),\n",
       " ('sub', 1),\n",
       " ('text', 1),\n",
       " ('quick', 1),\n",
       " ('brown', 1),\n",
       " ('fox', 1),\n",
       " ('jumps', 1),\n",
       " ('over', 1),\n",
       " ('lazy', 1),\n",
       " ('dog', 1),\n",
       " ('isn', 1),\n",
       " ('implicitly', 1),\n",
       " ('segmented', 1),\n",
       " ('spaces', 1),\n",
       " ('speaker', 1),\n",
       " ('would', 1),\n",
       " ('do', 1),\n",
       " ('raw', 1),\n",
       " ('43', 1),\n",
       " ('must', 1),\n",
       " ('explicitly', 1),\n",
       " ('split', 1),\n",
       " ('given', 1),\n",
       " ('space', 1),\n",
       " ('delimiter', 1),\n",
       " ('matching', 1),\n",
       " ('expression', 1),\n",
       " ('class', 1),\n",
       " ('represents', 1),\n",
       " ('more', 1),\n",
       " ('than', 1),\n",
       " ('one', 1),\n",
       " ('possible', 1),\n",
       " ('saves', 1),\n",
       " ('enough', 1),\n",
       " ('reproduce', 1),\n",
       " ('original', 1),\n",
       " ('so', 1),\n",
       " ('semantic', 1),\n",
       " ('analysis', 1),\n",
       " ('retrieves', 1),\n",
       " ('stores', 1),\n",
       " ('abstract', 1),\n",
       " ('syntax', 1),\n",
       " ('tree', 1),\n",
       " ('necessary', 1),\n",
       " ('order', 1),\n",
       " ('avoid', 1),\n",
       " ('loss', 1),\n",
       " ('case', 1),\n",
       " ('where', 1),\n",
       " ('numbers', 1),\n",
       " ('also', 1),\n",
       " ('valid', 1),\n",
       " ('identified', 1),\n",
       " ('based', 1),\n",
       " ('methods', 1),\n",
       " ('include', 1),\n",
       " ('sequences', 1),\n",
       " ('flag', 1),\n",
       " ('separating', 1),\n",
       " ('called', 1),\n",
       " ('delimiters', 1),\n",
       " ('explicit', 1),\n",
       " ('definition', 1),\n",
       " ('dictionary', 1),\n",
       " ('special', 1),\n",
       " ('including', 1),\n",
       " ('lexers', 1),\n",
       " ('because', 1),\n",
       " ('their', 1),\n",
       " ('categorized', 1),\n",
       " ('character', 1),\n",
       " ('content', 1),\n",
       " ('context', 1),\n",
       " ('within', 1),\n",
       " ('involve', 1),\n",
       " ('grammar', 1),\n",
       " ('elements', 1),\n",
       " ('operators', 1),\n",
       " ('grouping', 1),\n",
       " ('symbols', 1),\n",
       " ('type', 1),\n",
       " ('nouns', 1),\n",
       " ('verbs', 1),\n",
       " ('adjectives', 1),\n",
       " ('post', 1),\n",
       " ('either', 1),\n",
       " ('functions', 1),\n",
       " ('program', 1),\n",
       " ('generally', 1),\n",
       " ('combinations', 1),\n",
       " ('left', 1),\n",
       " ('typical', 1),\n",
       " ('recognizes', 1),\n",
       " ('parentheses', 1),\n",
       " ('but', 1),\n",
       " ('ensure', 1),\n",
       " ('each', 1),\n",
       " ('matched', 1),\n",
       " ('feeds', 1),\n",
       " ('representation', 1),\n",
       " ('enumerated', 1),\n",
       " ('list', 1),\n",
       " ('number', 1),\n",
       " ('representations', 1),\n",
       " ('identifier', 1),\n",
       " ('represented', 1),\n",
       " ('assignment', 1),\n",
       " ('addition', 1),\n",
       " ('etc', 1),\n",
       " ('which', 1),\n",
       " ('understood', 1),\n",
       " ('generator', 1),\n",
       " ('such', 1),\n",
       " ('generated', 1),\n",
       " ('automatically', 1),\n",
       " ('tool', 1),\n",
       " ('like', 1),\n",
       " ('hand', 1),\n",
       " ('crafted', 1),\n",
       " ('reads', 1),\n",
       " ('identifies', 1),\n",
       " ('lexemes', 1),\n",
       " ('categorizes', 1),\n",
       " ('them', 1),\n",
       " ('if', 1),\n",
       " ('finds', 1),\n",
       " ('invalid', 1),\n",
       " ('will', 1),\n",
       " ('report', 1),\n",
       " ('error', 1),\n",
       " ('following', 1),\n",
       " ('there', 1),\n",
       " ('interpreted', 1),\n",
       " ('loaded', 1),\n",
       " ('structures', 1),\n",
       " ('general', 1),\n",
       " ('interpretation', 1),\n",
       " ('compiling', 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(counts.items(),key=second,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 34),\n",
       " ('of', 14),\n",
       " ('tokens', 14),\n",
       " ('by', 11),\n",
       " ('in', 10),\n",
       " ('are', 8),\n",
       " ('is', 7),\n",
       " ('characters', 7),\n",
       " ('to', 7),\n",
       " ('or', 7),\n",
       " ('for', 6),\n",
       " ('with', 6),\n",
       " ('lexer', 6),\n",
       " ('used', 6),\n",
       " ('and', 5),\n",
       " ('be', 5),\n",
       " ('as', 5),\n",
       " ('often', 5),\n",
       " ('data', 5),\n",
       " ('string', 4),\n",
       " ('parser', 4),\n",
       " ('stream', 4),\n",
       " ('lexical', 4),\n",
       " ('analyzer', 4),\n",
       " ('input', 3),\n",
       " ('on', 3),\n",
       " ('example', 3),\n",
       " ('into', 3),\n",
       " ('regular', 3),\n",
       " ('information', 3),\n",
       " ('it', 3),\n",
       " ('this', 3),\n",
       " ('specific', 3),\n",
       " ('languages', 3),\n",
       " ('categories', 3),\n",
       " ('an', 3),\n",
       " ('process', 2),\n",
       " ('some', 2),\n",
       " ('other', 2),\n",
       " ('processing', 2),\n",
       " ('can', 2),\n",
       " ('task', 2),\n",
       " ('parsing', 2),\n",
       " ('natural', 2),\n",
       " ('language', 2),\n",
       " ('when', 2),\n",
       " ('token', 2),\n",
       " ('lexeme', 2),\n",
       " ('that', 2),\n",
       " ('typically', 2),\n",
       " ('from', 2),\n",
       " ('may', 2),\n",
       " ('identifiers', 2),\n",
       " ('rules', 2),\n",
       " ('identify', 2),\n",
       " ('expressions', 2),\n",
       " ('termed', 2),\n",
       " ('punctuation', 2),\n",
       " ('commonly', 2),\n",
       " ('use', 2),\n",
       " ('written', 2),\n",
       " ('programming', 2),\n",
       " ('defined', 2),\n",
       " ('categorize', 2),\n",
       " ('does', 2),\n",
       " ('nothing', 2),\n",
       " ('operator', 2),\n",
       " ('lex', 2),\n",
       " ('tokenizing', 2),\n",
       " ('tokenization', 1),\n",
       " ('demarcating', 1),\n",
       " ('possibly', 1),\n",
       " ('classifying', 1),\n",
       " ('sections', 1),\n",
       " ('resulting', 1),\n",
       " ('then', 1),\n",
       " ('passed', 1),\n",
       " ('form', 1),\n",
       " ('considered', 1),\n",
       " ('sub', 1),\n",
       " ('text', 1),\n",
       " ('quick', 1),\n",
       " ('brown', 1),\n",
       " ('fox', 1),\n",
       " ('jumps', 1),\n",
       " ('over', 1),\n",
       " ('lazy', 1),\n",
       " ('dog', 1),\n",
       " ('isn', 1),\n",
       " ('implicitly', 1),\n",
       " ('segmented', 1),\n",
       " ('spaces', 1),\n",
       " ('speaker', 1),\n",
       " ('would', 1),\n",
       " ('do', 1),\n",
       " ('raw', 1),\n",
       " ('43', 1),\n",
       " ('must', 1),\n",
       " ('explicitly', 1),\n",
       " ('split', 1),\n",
       " ('given', 1),\n",
       " ('space', 1),\n",
       " ('delimiter', 1),\n",
       " ('matching', 1),\n",
       " ('expression', 1),\n",
       " ('class', 1),\n",
       " ('represents', 1),\n",
       " ('more', 1),\n",
       " ('than', 1),\n",
       " ('one', 1),\n",
       " ('possible', 1),\n",
       " ('saves', 1),\n",
       " ('enough', 1),\n",
       " ('reproduce', 1),\n",
       " ('original', 1),\n",
       " ('so', 1),\n",
       " ('semantic', 1),\n",
       " ('analysis', 1),\n",
       " ('retrieves', 1),\n",
       " ('stores', 1),\n",
       " ('abstract', 1),\n",
       " ('syntax', 1),\n",
       " ('tree', 1),\n",
       " ('necessary', 1),\n",
       " ('order', 1),\n",
       " ('avoid', 1),\n",
       " ('loss', 1),\n",
       " ('case', 1),\n",
       " ('where', 1),\n",
       " ('numbers', 1),\n",
       " ('also', 1),\n",
       " ('valid', 1),\n",
       " ('identified', 1),\n",
       " ('based', 1),\n",
       " ('methods', 1),\n",
       " ('include', 1),\n",
       " ('sequences', 1),\n",
       " ('flag', 1),\n",
       " ('separating', 1),\n",
       " ('called', 1),\n",
       " ('delimiters', 1),\n",
       " ('explicit', 1),\n",
       " ('definition', 1),\n",
       " ('dictionary', 1),\n",
       " ('special', 1),\n",
       " ('including', 1),\n",
       " ('lexers', 1),\n",
       " ('because', 1),\n",
       " ('their', 1),\n",
       " ('categorized', 1),\n",
       " ('character', 1),\n",
       " ('content', 1),\n",
       " ('context', 1),\n",
       " ('within', 1),\n",
       " ('involve', 1),\n",
       " ('grammar', 1),\n",
       " ('elements', 1),\n",
       " ('operators', 1),\n",
       " ('grouping', 1),\n",
       " ('symbols', 1),\n",
       " ('type', 1),\n",
       " ('nouns', 1),\n",
       " ('verbs', 1),\n",
       " ('adjectives', 1),\n",
       " ('post', 1),\n",
       " ('either', 1),\n",
       " ('functions', 1),\n",
       " ('program', 1),\n",
       " ('generally', 1),\n",
       " ('combinations', 1),\n",
       " ('left', 1),\n",
       " ('typical', 1),\n",
       " ('recognizes', 1),\n",
       " ('parentheses', 1),\n",
       " ('but', 1),\n",
       " ('ensure', 1),\n",
       " ('each', 1),\n",
       " ('matched', 1),\n",
       " ('feeds', 1),\n",
       " ('representation', 1),\n",
       " ('enumerated', 1),\n",
       " ('list', 1),\n",
       " ('number', 1),\n",
       " ('representations', 1),\n",
       " ('identifier', 1),\n",
       " ('represented', 1),\n",
       " ('assignment', 1),\n",
       " ('addition', 1),\n",
       " ('etc', 1),\n",
       " ('which', 1),\n",
       " ('understood', 1),\n",
       " ('generator', 1),\n",
       " ('such', 1),\n",
       " ('generated', 1),\n",
       " ('automatically', 1),\n",
       " ('tool', 1),\n",
       " ('like', 1),\n",
       " ('hand', 1),\n",
       " ('crafted', 1),\n",
       " ('reads', 1),\n",
       " ('identifies', 1),\n",
       " ('lexemes', 1),\n",
       " ('categorizes', 1),\n",
       " ('them', 1),\n",
       " ('if', 1),\n",
       " ('finds', 1),\n",
       " ('invalid', 1),\n",
       " ('will', 1),\n",
       " ('report', 1),\n",
       " ('error', 1),\n",
       " ('following', 1),\n",
       " ('there', 1),\n",
       " ('interpreted', 1),\n",
       " ('loaded', 1),\n",
       " ('structures', 1),\n",
       " ('general', 1),\n",
       " ('interpretation', 1),\n",
       " ('compiling', 1)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(counts.items(),key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "296bc9f5e650645ada33988802a96dbced28fb57d089f124fd617aa4b6545454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
